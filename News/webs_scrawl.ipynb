{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba1cb0f",
   "metadata": {},
   "source": [
    "## **CNA English (Taiwan Focus)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75cc2f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "爬取進度:   1%|▎                                                    | 4/798 [00:05<17:18,  1.31s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     34\u001b[39m     response = requests.get(url, headers=headers, timeout=\u001b[32m10\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m     39\u001b[39m         pbar.update(\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "headers = {\n",
    "   'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "\n",
    "start_date = datetime.strptime(\"2025-04-01\", \"%Y-%m-%d\")\n",
    "end_date = datetime.strptime(\"2025-05-12\", \"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "num_days = (end_date - start_date).days + 1\n",
    "total_tasks = num_days * (20 - 2 + 1)\n",
    "\n",
    "\n",
    "with tqdm(total=total_tasks, desc=\"爬取進度\", ncols=100) as pbar:\n",
    "   current_date = start_date\n",
    "   while current_date <= end_date:\n",
    "       date_str = current_date.strftime(\"%Y%m%d\")\n",
    "       for i in range(2, 21):\n",
    "           article_id = f\"{i:04d}\"\n",
    "           full_id = f\"{date_str}{article_id}\"  \n",
    "           url = f\"https://focustaiwan.tw/cross-strait/{full_id}\"\n",
    "           try:\n",
    "               response = requests.get(url, headers=headers, timeout=10)\n",
    "               time.sleep(0.5)  \n",
    "\n",
    "\n",
    "               if response.status_code != 200:\n",
    "                   pbar.update(1)\n",
    "                   continue\n",
    "\n",
    "\n",
    "               soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "\n",
    "               title_tag = soup.select_one(\"span.h1t\")\n",
    "               date_tag = soup.select_one(\"div.updatetime\")\n",
    "               content_tags = soup.select(\"div.paragraph > p\")\n",
    "\n",
    "\n",
    "               if not (title_tag and date_tag and content_tags):\n",
    "                   pbar.update(1)\n",
    "                   continue\n",
    "\n",
    "\n",
    "               title = title_tag.text.strip()\n",
    "               date_raw = date_tag.text.strip()\n",
    "               date_obj = datetime.strptime(date_raw.split(\" \")[0], \"%m/%d/%Y\")\n",
    "               date = date_obj.strftime(\"%Y-%m-%d\")\n",
    "               content = \"\\n\".join(p.text.strip() for p in content_tags)\n",
    "\n",
    "\n",
    "               results.append({\n",
    "                   \"media_name\": \"中央社\",\n",
    "                   \"title\": title,\n",
    "                   \"date\": date,\n",
    "                   \"content\": content\n",
    "               })\n",
    "\n",
    "\n",
    "           except Exception as e:\n",
    "               pass \n",
    "\n",
    "\n",
    "           pbar.update(1)\n",
    "\n",
    "\n",
    "       current_date += timedelta(days=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"中央社兩岸新聞.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "   json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "print(f\"\\n✅ 完成，共擷取 {len(results)} 篇新聞。\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da3b0d8",
   "metadata": {},
   "source": [
    "# **Pts news**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddd7f4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- pip install --upgrade certifi\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2025.4.26)\n",
      " -- removing any existing file or link\n",
      " -- creating symlink to certifi certificate bundle\n",
      " -- setting permissions\n",
      " -- update complete\n",
      "ERROR: unknown command \"isinstall\" - maybe you meant \"install\"\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in /Users/ben/Library/Python/3.9/lib/python/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/ben/Library/Python/3.9/lib/python/site-packages (4.12.3)\n",
      "Requirement already satisfied: tqdm in /Users/ben/Library/Python/3.9/lib/python/site-packages (4.67.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ben/Library/Python/3.9/lib/python/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ben/Library/Python/3.9/lib/python/site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ben/Library/Python/3.9/lib/python/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ben/Library/Python/3.9/lib/python/site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/ben/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4) (2.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.32.0-py3-none-any.whl (9.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.4 MB 1.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: tqdm in /Users/ben/Library/Python/3.9/lib/python/site-packages (4.67.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/ben/Library/Python/3.9/lib/python/site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /Users/ben/Library/Python/3.9/lib/python/site-packages (from selenium) (2.2.1)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /Users/ben/Library/Python/3.9/lib/python/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /Users/ben/Library/Python/3.9/lib/python/site-packages (from selenium) (4.12.2)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
      "\u001b[K     |████████████████████████████████| 499 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: packaging in /Users/ben/Library/Python/3.9/lib/python/site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: requests in /Users/ben/Library/Python/3.9/lib/python/site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: idna in /Users/ben/Library/Python/3.9/lib/python/site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Collecting outcome\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/ben/Library/Python/3.9/lib/python/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/ben/Library/Python/3.9/lib/python/site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Collecting sortedcontainers\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: exceptiongroup in /Users/ben/Library/Python/3.9/lib/python/site-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Collecting wsproto>=0.14\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/ben/Library/Python/3.9/lib/python/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ben/Library/Python/3.9/lib/python/site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Installing collected packages: sortedcontainers, outcome, wsproto, trio, pysocks, trio-websocket, python-dotenv, webdriver-manager, selenium\n",
      "Successfully installed outcome-1.3.0.post0 pysocks-1.7.1 python-dotenv-1.1.0 selenium-4.32.0 sortedcontainers-2.4.0 trio-0.30.0 trio-websocket-0.12.2 webdriver-manager-4.0.2 wsproto-1.2.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! /Applications/Python\\ 3.13/Install\\ Certificates.command\n",
    "!pip3 isinstall --upgrade certifi\n",
    "!pip3 install requests beautifulsoup4 tqdm\n",
    "!pip3 install selenium webdriver-manager tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34d17486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "抓文章: 100%|██████████| 90/90 [02:13<00:00,  1.49s/篇]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 抓完！共 50 篇。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pip install selenium webdriver-manager tqdm\n",
    "\n",
    "import re, json, time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "START, END = datetime(2025,4,1), datetime(2025,5,12)\n",
    "CAT_URL     = \"https://news.pts.org.tw/category/9?page={}\"\n",
    "ARTICLE_RE  = re.compile(r\"/article/\\d+$\")\n",
    "\n",
    "opt = webdriver.ChromeOptions()\n",
    "opt.add_argument(\"--start-maximized\")\n",
    "opt.headless = False                          # 想隱藏改 True\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()),\n",
    "                          options=opt)\n",
    "\n",
    "article_urls = []\n",
    "page = 1\n",
    "while True:\n",
    "    driver.get(CAT_URL.format(page))\n",
    "\n",
    "    # 等 JS 把列表渲染好（偵測任何 <a> 符合 /article/123456）\n",
    "    WebDriverWait(driver, 15).until(\n",
    "        lambda d: d.execute_script(\n",
    "            \"return [...document.querySelectorAll('a')]\"\n",
    "            \".some(a=>a.getAttribute('href')?.match(/\\\\/article\\\\/\\\\d+$/))\"))\n",
    "\n",
    "    # ⬇︎ 把所有符合的 link 收集起來\n",
    "    links = driver.execute_script(\"\"\"\n",
    "        return [...new Set(\n",
    "          [...document.querySelectorAll('a')]\n",
    "            .map(a=>a.href)\n",
    "            .filter(h=>h && /\\\\/article\\\\/\\\\d+$/.test(h))\n",
    "        )];\n",
    "    \"\"\")\n",
    "    if not links: break\n",
    "    article_urls.extend(links)\n",
    "\n",
    "    # 如果本頁最舊一篇都 still >= START，就翻下一頁；否則停\n",
    "    dates_on_page = driver.execute_script(\"\"\"\n",
    "        return [...document.querySelectorAll('time, span, p')]\n",
    "               .map(el=>el.textContent.match(/(\\\\d{4})[\\\\/.-](\\\\d{1,2})[\\\\/.-](\\\\d{1,2})/))\n",
    "               .filter(Boolean).map(m=>m[0]);\n",
    "    \"\"\")\n",
    "    oldest = min([datetime.strptime(d, \"%Y/%m/%d\") for d in dates_on_page]\n",
    "                 or [END])\n",
    "    if oldest < START: break\n",
    "    page += 1\n",
    "    time.sleep(0.8)\n",
    "\n",
    "# ---------- 逐篇抓正文 ----------\n",
    "results = []\n",
    "bar = tqdm(article_urls, desc=\"抓文章\", unit=\"篇\")\n",
    "for url in bar:\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        WebDriverWait(driver, 12).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.CSS_SELECTOR, \"meta[property='article:published_time']\")))\n",
    "    except:           # 某些連結被撤稿照跳\n",
    "        continue\n",
    "\n",
    "    iso = driver.find_element(By.CSS_SELECTOR,\n",
    "          \"meta[property='article:published_time']\").get_attribute(\"content\")\n",
    "    pub_dt = datetime.fromisoformat(iso[:19])\n",
    "    if not (START <= pub_dt <= END):\n",
    "        continue\n",
    "\n",
    "    title = driver.find_element(By.CSS_SELECTOR,\n",
    "        \"meta[property='og:title']\").get_attribute(\"content\").strip()\n",
    "    paras = [p.text.strip() for p in driver.find_elements(By.CSS_SELECTOR,\"article p\") if p.text.strip()]\n",
    "    content = \"\\n\".join(paras)\n",
    "\n",
    "    results.append({\n",
    "        \"media_name\": \"公視新聞網\",\n",
    "        \"title\"     : title,\n",
    "        \"date\"      : pub_dt.strftime(\"%Y-%m-%d\"),\n",
    "        \"content\"   : content\n",
    "    })\n",
    "    time.sleep(0.25)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "with open(\"公視_兩岸新聞.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n✅ 抓完！共 {len(results)} 篇。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
