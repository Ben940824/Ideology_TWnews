{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6be4e6dd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-31T20:59:28.184609Z",
     "iopub.status.busy": "2025-05-31T20:59:28.184415Z",
     "iopub.status.idle": "2025-05-31T21:08:35.455797Z",
     "shell.execute_reply": "2025-05-31T21:08:35.455037Z"
    },
    "papermill": {
     "duration": 547.277935,
     "end_time": "2025-05-31T21:08:35.459563",
     "exception": false,
     "start_time": "2025-05-31T20:59:28.181628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始載入數據並準備英文文本（標題與標題+內容）...\n",
      "數據載入與英文文本準備完成。共 3166 篇新聞。\n",
      "--------------------------------------------------\n",
      "開始對每個文本模式和每個模型執行 5 摺分層交叉驗證...\n",
      "\n",
      "--- 正在處理模型: Logistic Regression, 文本模式: title ---\n",
      "  開始建立 TF-IDF 向量（針對 title 文本）...\n",
      "  TF-IDF 向量建立完成。詞彙量: 1979\n",
      "  特徵矩陣形狀（文件數, 特徵數）: (3166, 1979)\n",
      "  --------------------------------------------------\n",
      "    摺疊 0 完成。F1-Macro: 0.6101, 準確率: 0.6562, 耗時: 0.02秒, 損失: 0.8208\n",
      "    摺疊 1 完成。F1-Macro: 0.6186, 準確率: 0.6651, 耗時: 0.02秒, 損失: 0.7984\n",
      "    摺疊 2 完成。F1-Macro: 0.5747, 準確率: 0.6367, 耗時: 0.02秒, 損失: 0.8143\n",
      "    摺疊 3 完成。F1-Macro: 0.5694, 準確率: 0.6256, 耗時: 0.02秒, 損失: 0.8310\n",
      "    摺疊 4 完成。F1-Macro: 0.6194, 準確率: 0.6682, 耗時: 0.02秒, 損失: 0.7877\n",
      "\n",
      "--- 正在處理模型: Logistic Regression, 文本模式: title+content ---\n",
      "  開始建立 TF-IDF 向量（針對 title+content 文本）...\n",
      "  TF-IDF 向量建立完成。詞彙量: 9242\n",
      "  特徵矩陣形狀（文件數, 特徵數）: (3166, 9242)\n",
      "  --------------------------------------------------\n",
      "    摺疊 0 完成。F1-Macro: 0.6494, 準確率: 0.6940, 耗時: 0.10秒, 損失: 0.7627\n",
      "    摺疊 1 完成。F1-Macro: 0.6720, 準確率: 0.7204, 耗時: 0.12秒, 損失: 0.7293\n",
      "    摺疊 2 完成。F1-Macro: 0.6401, 準確率: 0.6825, 耗時: 0.11秒, 損失: 0.7415\n",
      "    摺疊 3 完成。F1-Macro: 0.6452, 準確率: 0.6761, 耗時: 0.11秒, 損失: 0.7785\n",
      "    摺疊 4 完成。F1-Macro: 0.6601, 準確率: 0.6967, 耗時: 0.10秒, 損失: 0.7395\n",
      "\n",
      "--- 正在處理模型: SVM, 文本模式: title ---\n",
      "  開始建立 TF-IDF 向量（針對 title 文本）...\n",
      "  TF-IDF 向量建立完成。詞彙量: 1979\n",
      "  特徵矩陣形狀（文件數, 特徵數）: (3166, 1979)\n",
      "  --------------------------------------------------\n",
      "    摺疊 0 完成。F1-Macro: 0.6266, 準確率: 0.6751, 耗時: 6.31秒, 損失: 0.7782\n",
      "    摺疊 1 完成。F1-Macro: 0.6253, 準確率: 0.6761, 耗時: 6.34秒, 損失: 0.7350\n",
      "    摺疊 2 完成。F1-Macro: 0.5775, 準確率: 0.6398, 耗時: 6.34秒, 損失: 0.7708\n",
      "    摺疊 3 完成。F1-Macro: 0.5747, 準確率: 0.6367, 耗時: 6.35秒, 損失: 0.8080\n",
      "    摺疊 4 完成。F1-Macro: 0.6236, 準確率: 0.6761, 耗時: 6.41秒, 損失: 0.7235\n",
      "\n",
      "--- 正在處理模型: SVM, 文本模式: title+content ---\n",
      "  開始建立 TF-IDF 向量（針對 title+content 文本）...\n",
      "  TF-IDF 向量建立完成。詞彙量: 9242\n",
      "  特徵矩陣形狀（文件數, 特徵數）: (3166, 9242)\n",
      "  --------------------------------------------------\n",
      "    摺疊 0 完成。F1-Macro: 0.6686, 準確率: 0.7050, 耗時: 59.90秒, 損失: 0.7167\n",
      "    摺疊 1 完成。F1-Macro: 0.6892, 準確率: 0.7314, 耗時: 60.27秒, 損失: 0.6477\n",
      "    摺疊 2 完成。F1-Macro: 0.6632, 準確率: 0.7030, 耗時: 59.32秒, 損失: 0.6687\n",
      "    摺疊 3 完成。F1-Macro: 0.6517, 準確率: 0.6825, 耗時: 60.46秒, 損失: 0.7305\n",
      "    摺疊 4 完成。F1-Macro: 0.6594, 準確率: 0.6935, 耗時: 59.95秒, 損失: 0.6805\n",
      "\n",
      "--- 正在處理模型: XGBoost, 文本模式: title ---\n",
      "  開始建立 TF-IDF 向量（針對 title 文本）...\n",
      "  TF-IDF 向量建立完成。詞彙量: 1979\n",
      "  特徵矩陣形狀（文件數, 特徵數）: (3166, 1979)\n",
      "  --------------------------------------------------\n",
      "    摺疊 0 完成。F1-Macro: 0.6001, 準確率: 0.6309, 耗時: 3.29秒, 損失: 0.8325\n",
      "    摺疊 1 完成。F1-Macro: 0.6328, 準確率: 0.6619, 耗時: 3.35秒, 損失: 0.8000\n",
      "    摺疊 2 完成。F1-Macro: 0.6086, 準確率: 0.6509, 耗時: 4.50秒, 損失: 0.8061\n",
      "    摺疊 3 完成。F1-Macro: 0.5669, 準確率: 0.6019, 耗時: 3.19秒, 損失: 0.8770\n",
      "    摺疊 4 完成。F1-Macro: 0.6208, 準確率: 0.6540, 耗時: 3.32秒, 損失: 0.7972\n",
      "\n",
      "--- 正在處理模型: XGBoost, 文本模式: title+content ---\n",
      "  開始建立 TF-IDF 向量（針對 title+content 文本）...\n",
      "  TF-IDF 向量建立完成。詞彙量: 9242\n",
      "  特徵矩陣形狀（文件數, 特徵數）: (3166, 9242)\n",
      "  --------------------------------------------------\n",
      "    摺疊 0 完成。F1-Macro: 0.6679, 準確率: 0.7003, 耗時: 38.32秒, 損失: 0.7861\n",
      "    摺疊 1 完成。F1-Macro: 0.6920, 準確率: 0.7156, 耗時: 38.28秒, 損失: 0.6976\n",
      "    摺疊 2 完成。F1-Macro: 0.6925, 準確率: 0.7188, 耗時: 36.71秒, 損失: 0.7236\n",
      "    摺疊 3 完成。F1-Macro: 0.6687, 準確率: 0.6998, 耗時: 39.85秒, 損失: 0.7869\n",
      "    摺疊 4 完成。F1-Macro: 0.6740, 準確率: 0.6983, 耗時: 38.18秒, 損失: 0.7530\n",
      "\n",
      "--------------------------------------------------\n",
      "開始組裝最終結果列表...\n",
      "最終結果列表組裝完成。\n",
      "\n",
      "--- 分類結果（英文新聞）---\n",
      "   fold                                exp  best_macro_f1  time_sec       acc  \\\n",
      "0     0          Logistic Regression_title       0.610147      0.02  0.656151   \n",
      "1     0  Logistic Regression_title+content       0.649374      0.10  0.694006   \n",
      "2     0                          SVM_title       0.626585      6.31  0.675079   \n",
      "3     0                  SVM_title+content       0.668620     59.90  0.705047   \n",
      "4     0                      XGBoost_title       0.600069      3.29  0.630915   \n",
      "\n",
      "   f1_macro  f1_weighted  prec_macro  recall_macro      loss  \n",
      "0  0.610147     0.642608    0.653236      0.599505  0.820784  \n",
      "1  0.649374     0.683541    0.673153      0.642292  0.762747  \n",
      "2  0.626585     0.659024    0.693515      0.611875  0.778196  \n",
      "3  0.668620     0.696654    0.695499      0.658477  0.716677  \n",
      "4  0.600069     0.625546    0.611832      0.595106  0.832506  \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, log_loss\n",
    "\n",
    "# --- 1. 數據載入與英文文本預處理 ---\n",
    "# 儲存不同文本輸入模式的處理結果\n",
    "documents_title_only = []      # 僅包含英文標題的文本列表\n",
    "documents_title_plus_content = [] # 包含英文標題+內容的文本列表\n",
    "labels = []                    # 儲存數值標籤（對兩種模式共用）\n",
    "\n",
    "print(\"開始載入數據並準備英文文本（標題與標題+內容）...\")\n",
    "file_path = '/kaggle/input/taiwan-political-news-dataset/news_training_with_translations.csv'\n",
    "\n",
    "try:\n",
    "    with open(file_path, newline='', encoding='utf-8') as f:\n",
    "        rows = csv.reader(f)\n",
    "        header = next(rows) # 讀取標頭\n",
    "        \n",
    "        # 從標頭確定欄位索引\n",
    "        try:\n",
    "            title_en_idx = header.index('title_en')\n",
    "            content_en_idx = header.index('content_en')\n",
    "            label_encoded_idx = header.index('label_encoded')\n",
    "        except ValueError as e:\n",
    "            print(f\"錯誤：CSV 標頭中缺少預期的欄位: {e}\")\n",
    "            print(\"請確保 'title_en', 'content_en' 和 'label_encoded' 欄位存在。\")\n",
    "            exit() # 如果關鍵欄位遺失，程式終止\n",
    "\n",
    "        for i, row in enumerate(rows):\n",
    "            # 取得英文標題和內容\n",
    "            title_en = row[title_en_idx]\n",
    "            content_en = row[content_en_idx]\n",
    "            \n",
    "            # 取得標籤\n",
    "            try:\n",
    "                label = int(row[label_encoded_idx])\n",
    "            except (ValueError, IndexError):\n",
    "                print(f\"警告：跳過第 {i+2} 行（數據行索引 {i}），因為標籤無效或缺失: {row}\")\n",
    "                continue # 跳過標籤有問題的行\n",
    "\n",
    "            # 準備「僅標題」的文本\n",
    "            processed_title = ' '.join([word for word in title_en.split() if len(word) > 1])\n",
    "            \n",
    "            # 準備「標題 + 內容」的文本\n",
    "            full_text_en = title_en + ' ' + content_en\n",
    "            processed_title_plus_content = ' '.join([word for word in full_text_en.split() if len(word) > 1])\n",
    "\n",
    "            # 只有當兩種文本模式都能產生有效內容時才加入數據集\n",
    "            if processed_title and processed_title_plus_content: \n",
    "                documents_title_only.append(processed_title)\n",
    "                documents_title_plus_content.append(processed_title_plus_content)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                print(f\"警告：第 {i+2} 行的標題或內容處理後為空，已跳過。\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"錯誤：找不到檔案 '{file_path}'。請檢查檔案路徑是否正確。\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"讀取檔案時發生錯誤：{e}\")\n",
    "    exit()\n",
    "\n",
    "print(f\"數據載入與英文文本準備完成。共 {len(labels)} 篇新聞。\")\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "# 將標籤轉換為 NumPy 陣列\n",
    "y = np.array(labels)\n",
    "\n",
    "# 定義要測試的模型\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, solver='liblinear', multi_class='ovr', max_iter=2000),\n",
    "    'SVC': SVC(random_state=42, probability=True), # probability=True 用於計算 log_loss\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric='mlogloss', objective='multi:softprob') # 移除 use_label_encoder\n",
    "}\n",
    "\n",
    "# 定義模型名稱到輸出實驗名稱的映射\n",
    "model_exp_name_map = {\n",
    "    'LogisticRegression': 'Logistic Regression',\n",
    "    'SVC': 'SVM',\n",
    "    'XGBoost': 'XGBoost'\n",
    "}\n",
    "\n",
    "# 定義用於排序的各個部分的**列表**，以確保明確的順序和正確的長度\n",
    "model_display_order_list = ['LogisticRegression', 'SVC', 'XGBoost'] # 內部模型鍵的排序\n",
    "mode_display_order_list = ['title', 'title+content'] # 模式鍵的排序\n",
    "\n",
    "# 建立從內部鍵到排序值的映射\n",
    "model_sort_values = {name: i for i, name in enumerate(model_display_order_list)}\n",
    "mode_sort_values = {name: i for i, name in enumerate(mode_display_order_list)}\n",
    "\n",
    "\n",
    "# 定義兩種文本輸入模式及其對應的數據\n",
    "data_modes = {\n",
    "    'title': documents_title_only,\n",
    "    'title+content': documents_title_plus_content\n",
    "}\n",
    "\n",
    "# 準備所有結果的列表\n",
    "all_results = []\n",
    "\n",
    "# 設定 5 摺分層交叉驗證\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42) # random_state 確保結果可重現\n",
    "\n",
    "print(f\"開始對每個文本模式和每個模型執行 {n_splits} 摺分層交叉驗證...\")\n",
    "\n",
    "# Store results temporarily for proper per-fold grouping and sorting\n",
    "temp_results_per_fold = {f: [] for f in range(n_splits)}\n",
    "\n",
    "\n",
    "for model_key, model_instance_template in models.items(): # 使用 model_key 來獲取原始模型名稱\n",
    "    # 根據映射取得要顯示在 exp 欄位中的名稱\n",
    "    exp_model_display_name = model_exp_name_map.get(model_key, model_key) # 如果沒有映射則使用原始名稱\n",
    "\n",
    "    for mode_name, documents in data_modes.items():\n",
    "        print(f\"\\n--- 正在處理模型: {exp_model_display_name}, 文本模式: {mode_name} ---\")\n",
    "\n",
    "        # --- 2. TF-IDF 特徵提取（針對當前文本模式）---\n",
    "        print(f\"  開始建立 TF-IDF 向量（針對 {mode_name} 文本）...\")\n",
    "        tfidf_vectorizer = TfidfVectorizer(min_df=5, max_df=0.8, stop_words='english')\n",
    "        X_mode = tfidf_vectorizer.fit_transform(documents) # X_mode 為當前模式的 TF-IDF 特徵矩陣\n",
    "        print(f\"  TF-IDF 向量建立完成。詞彙量: {len(tfidf_vectorizer.vocabulary_)}\")\n",
    "        print(f\"  特徵矩陣形狀（文件數, 特徵數）: {X_mode.shape}\")\n",
    "        print(\"  --------------------------------------------------\")\n",
    "\n",
    "        # 複製模型實例，以確保每個實驗回合都是從一個乾淨的模型開始\n",
    "        model_instance = model_instance_template.__class__(**model_instance_template.get_params())\n",
    "\n",
    "        for fold, (train_index, test_index) in enumerate(skf.split(X_mode, y)):\n",
    "            start_time_fold = time.time()\n",
    "\n",
    "            X_train, X_test = X_mode[train_index], X_mode[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # 訓練模型\n",
    "            model_instance.fit(X_train, y_train)\n",
    "\n",
    "            # 進行預測\n",
    "            y_pred = model_instance.predict(X_test)\n",
    "            \n",
    "            # 取得預測機率值以計算 log_loss\n",
    "            if hasattr(model_instance, 'predict_proba'):\n",
    "                y_pred_proba = model_instance.predict_proba(X_test)\n",
    "            else:\n",
    "                print(f\"    警告: 模型 {exp_model_display_name} 沒有 predict_proba 方法，log_loss 可能會受到影響。\")\n",
    "                # 如果無法取得機率，則使用均勻分佈機率\n",
    "                y_pred_proba = np.full((len(y_test), len(np.unique(y))), 1/len(np.unique(y)))\n",
    "\n",
    "            # 計算性能指標\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "            f1_weighted = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            prec_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "            recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "            \n",
    "            # 計算對數損失 (log_loss)\n",
    "            try:\n",
    "                current_loss = log_loss(y_test, y_pred_proba, labels=np.unique(y))\n",
    "            except ValueError as e:\n",
    "                print(f\"    警告：無法為模型 {exp_model_display_name} 在 Fold {fold} 計算 log_loss: {e}\")\n",
    "                current_loss = np.nan\n",
    "\n",
    "            end_time_fold = time.time()\n",
    "            time_sec = round(end_time_fold - start_time_fold, 2)\n",
    "\n",
    "            # 儲存每個摺疊的結果和指標\n",
    "            fold_row = {\n",
    "                'fold': fold,\n",
    "                'exp': f'{exp_model_display_name}_{mode_name}', # 實驗名稱現在使用映射後的顯示名稱\n",
    "                'best_macro_f1': round(f1_macro, 15),\n",
    "                'time_sec': time_sec,\n",
    "                'acc': round(accuracy, 15),\n",
    "                'f1_macro': round(f1_macro, 15),\n",
    "                'f1_weighted': round(f1_weighted, 15),\n",
    "                'prec_macro': round(prec_macro, 15),\n",
    "                'recall_macro': round(recall_macro, 15),\n",
    "                'loss': round(current_loss, 15),\n",
    "                'original_model_key': model_key, # 儲存原始模型鍵用於排序\n",
    "                'mode_name_key': mode_name # 儲存模式鍵用於排序\n",
    "            }\n",
    "            temp_results_per_fold[fold].append(fold_row) # 暫存到對應的摺疊列表中\n",
    "\n",
    "            print(f\"    摺疊 {fold} 完成。F1-Macro: {f1_macro:.4f}, 準確率: {accuracy:.4f}, 耗時: {time_sec:.2f}秒, 損失: {current_loss:.4f}\")\n",
    "\n",
    "# 現在，將所有摺疊的結果按照您指定的順序組裝到最終列表中\n",
    "print(\"\\n--------------------------------------------------\")\n",
    "print(\"開始組裝最終結果列表...\")\n",
    "\n",
    "# 自定義排序函數，用於 `exp` 欄位 (現在直接使用儲存的鍵)\n",
    "def custom_exp_sort_key(row_dict):\n",
    "    original_model_key = row_dict['original_model_key']\n",
    "    mode_name_key = row_dict['mode_name_key']\n",
    "    \n",
    "    # 獲取模型和模式的排序值，使用明確的列表長度作為預設值\n",
    "    model_order = model_sort_values.get(original_model_key, len(model_display_order_list))\n",
    "    mode_order = mode_sort_values.get(mode_name_key, len(mode_display_order_list))\n",
    "    \n",
    "    return (model_order, mode_order)\n",
    "\n",
    "# 遍歷每個摺疊，並在每個摺疊內部按照 custom_exp_sort_key 排序\n",
    "for fold_num in sorted(temp_results_per_fold.keys()):\n",
    "    # 對當前摺疊的結果進行排序\n",
    "    sorted_fold_results = sorted(temp_results_per_fold[fold_num], key=lambda x: custom_exp_sort_key(x))\n",
    "    all_results.extend(sorted_fold_results) # 將排序後的結果添加到最終列表\n",
    "\n",
    "print(\"最終結果列表組裝完成。\")\n",
    "print(\"\\n--- 分類結果（英文新聞）---\")\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.drop(columns=['original_model_key', 'mode_name_key'])\n",
    "results_df.to_csv('results_summary.csv', index=False, float_format='%.15f')\n",
    "print(results_df.head())  \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7533682,
     "sourceId": 12013178,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 551.869682,
   "end_time": "2025-05-31T21:08:35.979683",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-31T20:59:24.110001",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
